{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pretraining on unlabeled data\n",
    "\n",
    "Topics:\n",
    "- evaluating the quality of generated text\n",
    "- load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "from typing import Optional\n",
    "\n",
    "import torch \n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from gpt import GPTModel, GPTConfig, generate_text_simple, create_dataloader_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Evaluating generative text models\n",
    "\n",
    "### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embedding_layer): Embedding(50257, 768)\n",
       "  (position_embedding_layer): Embedding(256, 768)\n",
       "  (embedding_dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = GPTConfig(\n",
    "    vocabulary_size=50257,\n",
    "    context_length=256,\n",
    "    embedding_dim=768,\n",
    "    num_heads=12,\n",
    "    num_transformers=12,\n",
    "    dropout_rate=0.1,\n",
    "    qkv_bias=False\n",
    ")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(**asdict(GPT_CONFIG_124M))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " every effort moves you rentingetic minion mobilized Macicone heterogeneity\u0000achaRAM\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_tokens = \"every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    token_ids=text_to_token_ids(start_tokens, tokenizer),\n",
    "    num_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M.context_length\n",
    ")\n",
    "print(f\"Output text:\\n {token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves al\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],  # every effort moves\n",
    "                       [40,    1107, 588]])  # I really like\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 435],   # effort moves you\n",
    "                        [1107, 588, 11311]]) # really like chocolate\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "print(probabilities.shape)\n",
    "\n",
    "token_ids = torch.argmax(probabilities, dim=-1, keepdim=True)\n",
    "print(f\"Token IDs:\\n {token_ids}\")\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "tensor(10.8122)\n",
      "tensor(49623.7266)\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)\n",
    "\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"Total characters: {total_characters}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "validation_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    window_length=GPT_CONFIG_124M.context_length,\n",
    "    stride=GPT_CONFIG_124M.context_length,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "validation_loader = create_dataloader_v1(\n",
    "    validation_data,\n",
    "    window_length=GPT_CONFIG_124M.context_length,\n",
    "    stride=GPT_CONFIG_124M.context_length,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    logits_flat = logits.flatten(0, 1)\n",
    "\n",
    "    target_batch = target_batch.to(device)\n",
    "    target_flat = target_batch.flatten()\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(logits_flat, target_flat)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches: Optional[int] = None):\n",
    "    \"\"\"Calculates the average loss of the first n batches in the data loader.\"\"\"\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    total_loss = 0.\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.939951525794135\n",
      "Validation loss: 6.85154390335083\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    validation_loss = calc_loss_loader(validation_loader, model, device)\n",
    "print(f\"Training loss: {train_loss}\")\n",
    "print(f\"Validation loss: {validation_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model, \n",
    "    train_loader, validation_loader, \n",
    "    device, \n",
    "    num_batches: int\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches)\n",
    "        validation_loss = calc_loss_loader(validation_loader, model, device, num_batches)\n",
    "    model.train()\n",
    "    return train_loss, validation_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model: GPTModel, tokenizer, device, start_tokens: str):\n",
    "    model.eval()\n",
    "    context_size = model.position_embedding_layer.weight.shape[0]\n",
    "    token_ids = text_to_token_ids(start_tokens, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_token_ids = generate_text_simple(\n",
    "            model, token_ids, num_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    generated_tokens = token_ids_to_text(generated_token_ids, tokenizer)\n",
    "    print(generated_tokens.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_simple(\n",
    "    model: GPTModel,\n",
    "    train_loader, validation_loader, \n",
    "    optimizer, device, num_epochs, \n",
    "    eval_freq: int, eval_n_batches: int, \n",
    "    start_tokens: str, tokenizer\n",
    "):\n",
    "    (\n",
    "        train_losses, \n",
    "        validation_losses, \n",
    "        num_tokens_seen_list\n",
    "    ) = [], [], []\n",
    "    num_tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # Reset loss gradients from the previous batch iteration\n",
    "            optimizer.zero_grad()  \n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            num_tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Evaluate model at specified frequency\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, validation_loss = evaluate_model(\n",
    "                    model, \n",
    "                    train_loader, \n",
    "                    validation_loader, \n",
    "                    device, \n",
    "                    eval_n_batches\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                validation_losses.append(validation_loss)\n",
    "                num_tokens_seen_list.append(num_tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch + 1} (Step {global_step: 06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Validation loss {validation_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, device, start_tokens)\n",
    "\n",
    "    return train_losses, validation_losses, num_tokens_seen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step  00000): Train loss 10.948, Validation loss 10.935\n",
      "Ep 1 (Step  00005): Train loss 9.748, Validation loss 9.768\n",
      "Every effort moves you his hisy hisyy hisy hisyyyyyyyyyyyyyyyy hisyy hisy hisyy his hisy hisy hisy hisyyy hisyyy hisy\n",
      "Ep 2 (Step  00010): Train loss 8.108, Validation loss 8.308\n",
      "Ep 2 (Step  00015): Train loss 6.912, Validation loss 7.200\n",
      "Every effort moves you his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his his\n",
      "Ep 3 (Step  00020): Train loss 6.334, Validation loss 6.735\n",
      "Ep 3 (Step  00025): Train loss 6.104, Validation loss 6.632\n",
      "Every effort moves you the... the the. the the the the.... the the the the the the. the. the the the the. the the. the the the the. the. the the the the. the the. the the the\n",
      "Ep 4 (Step  00030): Train loss 6.062, Validation loss 6.673\n",
      "Ep 4 (Step  00035): Train loss 6.065, Validation loss 6.741\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 5 (Step  00040): Train loss 5.988, Validation loss 6.768\n",
      "Every effort moves you                                                  \n",
      "Ep 6 (Step  00045): Train loss 6.004, Validation loss 6.770\n",
      "Ep 6 (Step  00050): Train loss 5.995, Validation loss 6.775\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 7 (Step  00055): Train loss 6.024, Validation loss 6.805\n",
      "Ep 7 (Step  00060): Train loss 5.977, Validation loss 6.828\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 8 (Step  00065): Train loss 5.933, Validation loss 6.824\n",
      "Ep 8 (Step  00070): Train loss 5.984, Validation loss 6.830\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 9 (Step  00075): Train loss 5.948, Validation loss 6.827\n",
      "Ep 9 (Step  00080): Train loss 5.958, Validation loss 6.842\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 10 (Step  00085): Train loss 5.922, Validation loss 6.858\n",
      "Every effort moves you..,......,,,...,,                                 \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(**asdict(GPT_CONFIG_124M))\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, validation_losses, num_tokens_seen_list = train_model_simple(\n",
    "    model, \n",
    "    train_loader, validation_loader, \n",
    "    optimizer, device, num_epochs, \n",
    "    eval_freq=5, eval_n_batches=5, \n",
    "    start_tokens=\"Every effort moves you\", \n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, validation_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, \n",
    "        validation_losses, \n",
    "        linestyle=\"-.\", \n",
    "        label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "num_epochs_list = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(num_epochs_list, num_tokens_seen_list, train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you..,......,,,...,,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    token_ids=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    num_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M.context_length\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model, \n",
    "    token_ids, \n",
    "    num_new_tokens, \n",
    "    context_size, \n",
    "    temperature=0.0, \n",
    "    top_k=None, \n",
    "    eos_id=None\n",
    "):\n",
    "    for _ in range(num_new_tokens):\n",
    "        token_ids_in_context = token_ids[:, -context_size:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(token_ids_in_context)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        if top_k is not None:\n",
    "            top_k_logits, _ = torch.topk(logits, top_k)\n",
    "            kth_logit = top_k_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < kth_logit, \n",
    "                torch.tensor(float(\"-inf\")).to(logits.device), \n",
    "                logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probabilities, num_samples=1)\n",
    "        else:\n",
    "            next_token_id = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        if next_token_id == eos_id:\n",
    "            break\n",
    "        \n",
    "        token_ids = torch.cat((token_ids, next_token_id), dim=1)\n",
    "        \n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you't I. I it a,. his that \" my-- \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    token_ids=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    num_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M.context_length,\n",
    "    top_k=25,\n",
    "    temperature=1.4,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x37f6dcb20>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"num_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"num_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"num_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"num_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(\n",
    "            f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):           #1\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):     #2\n",
    "        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "\n",
    "        gpt.trf_blocks[b].attn.W_query.weight = assign(gpt.trf_blocks[b].attn.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].attn.W_key.weight = assign(gpt.trf_blocks[b].attn.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].attn.W_value.weight = assign(gpt.trf_blocks[b].attn.W_value.weight, v_w.T)\n",
    "        \n",
    "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].attn.W_query.bias = assign(gpt.trf_blocks[b].attn.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].attn.W_key.bias = assign(gpt.trf_blocks[b].attn.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].attn.W_value.bias = assign(gpt.trf_blocks[b].attn.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].attn.out_projection.weight = assign(\n",
    "            gpt.trf_blocks[b].attn.out_projection.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].attn.out_projection.bias = assign(\n",
    "            gpt.trf_blocks[b].attn.out_projection.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "        \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    token_ids=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    num_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
